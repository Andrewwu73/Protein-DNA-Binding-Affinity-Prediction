{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "'''\n",
    "Sourced from Tensorflow's tutorial on Variational Autoencoders.\n",
    "'''\n",
    "\n",
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim, shape_of_input, reg_coeff, dropout_rate):\n",
    "    super(CVAE, self).__init__()\n",
    "    #print(shape_of_input)\n",
    "    self.latent_dim = latent_dim\n",
    "    self.regularizer = tf.keras.regularizers.l2(l2=reg_coeff)\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=shape_of_input),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=(4,1), strides=1, activation='relu', kernel_regularizer=self.regularizer),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 2), strides=2, padding='valid'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=64, kernel_size=(4,1), strides=1, activation='relu', kernel_regularizer=self.regularizer),\n",
    "            tf.keras.layers.MaxPool2D(\n",
    "                pool_size=(2, 1), strides=1, padding='valid'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "\n",
    "            tf.keras.layers.Dense(124, kernel_regularizer=self.regularizer),\n",
    "\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim, kernel_regularizer=self.regularizer),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(units=shape_of_input[0]*shape_of_input[1], activation=tf.nn.relu),\n",
    "            tf.keras.layers.Reshape(target_shape=(shape_of_input[0], shape_of_input[1],1)),\n",
    "            # tf.keras.layers.UpSampling2D(size=(2, 1)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=(4,1), strides=1, padding='same',\n",
    "                activation='relu',kernel_regularizer=self.regularizer),\n",
    "            # tf.keras.layers.UpSampling2D(size=(2, 2)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=(4,1), strides=1, padding='same',\n",
    "                activation='relu', kernel_regularizer=self.regularizer),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=1, kernel_size=1, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test set ELBO: -1825.4027099609375, time elapse for current epoch: 0:09:13.764576\n",
      "Epoch: 2, Test set ELBO: -1814.2830810546875, time elapse for current epoch: 0:09:15.881803\n",
      "Epoch: 3, Test set ELBO: -1804.86279296875, time elapse for current epoch: 0:09:13.043028\n",
      "Epoch: 4, Test set ELBO: -1810.5401611328125, time elapse for current epoch: 1:02:17.860193\n",
      "Epoch: 5, Test set ELBO: -1801.7003173828125, time elapse for current epoch: 0:10:33.320202\n",
      "Epoch: 6, Test set ELBO: -1799.4583740234375, time elapse for current epoch: 0:10:19.771605\n",
      "Elbo > 1800. Ending training.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "#from TF_VAE_DNA import CVAE\n",
    "import datetime as time\n",
    "#from generate_dna_onehot import obtainDNAData\n",
    "'''\n",
    "Sourced from Tensorflow's tutorial on VAEs.\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.Adam(1e-3)\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)  #Try alternate loss functions, maybe interesting ones that penalize large mutations rather than small mutations\n",
    "  logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "\n",
    "#@tf.function\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "## dataset_directory = \"../../Datasets/Protein-DNA Complex/DNADataset.csv\"\n",
    "#dataset_directory = \"../../Datasets/FinalDatasets/5SpeciesDNA.csv\"\n",
    "#dna_dataset_obtainer = obtainDNAData(dataset_directory)\n",
    "#train_dataset, test_dataset = dna_dataset_obtainer.obtainData()\n",
    "#train_dataset = tf.cast(tf.convert_to_tensor(train_dataset), dtype=tf.float32)\n",
    "#test_dataset = tf.cast(tf.convert_to_tensor(test_dataset), dtype=tf.float32)\n",
    "\n",
    "## train_dataset = []#TODO 100x4 for one hot encoding of DNA sequence, pad 0s to make sure have space for longest DNA sequence\n",
    "#shape_of_input = tf.expand_dims(train_dataset[0], axis=2)\n",
    "## shape_of_input = tf.expand_dims(shape_of_input, axis=3)\n",
    "\n",
    "#shape_of_input = shape_of_input.shape\n",
    "\n",
    "def train(epochs = 15, latent_dim=32, reg_coeff = 0.0001, dropout_rate = 0):\n",
    "    model = CVAE(latent_dim, shape_of_input, reg_coeff, dropout_rate)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "      start_time = time.datetime.now()\n",
    "      _train_step = tf.function(train_step)\n",
    "      for train_x in train_dataset:\n",
    "        #shape_of_inputx = tf.expand_dims(train_x, axis=2)\n",
    "        shape_of_inputx = tf.expand_dims(train_x, axis=0)\n",
    "        _train_step(model, shape_of_inputx, optimizer)\n",
    "      end_time = time.datetime.now()\n",
    "\n",
    "      loss = tf.keras.metrics.Mean()\n",
    "      for test_x in test_dataset:\n",
    "        #shape_of_inputtest = tf.expand_dims(test_x, axis=2)\n",
    "        shape_of_inputtest = tf.expand_dims(test_x, axis=0)\n",
    "        loss(compute_loss(model, shape_of_inputtest))\n",
    "      elbo = -loss.result()\n",
    "      # display.clear_output(wait=False)\n",
    "      print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "            .format(epoch, elbo, end_time - start_time))\n",
    "      if elbo > -1800: \n",
    "            print('Elbo > -1800. Ending training.')\n",
    "            break\n",
    "    model.save_weights('Protein_VAE')\n",
    "    return model\n",
    "\n",
    "# hypers = {\"latent_dim\": [16, 32, 64, 128], \"reg_coeff\": [0.0001, 0.00001, 0.00005], \"dropout_rate\": [0.01, 0.001, 0.0001]}\n",
    "# for l in range(3):\n",
    "#     for r in range(3):\n",
    "#         for d in range(3):\n",
    "#             print(\"\\n\\nNew Epoch:\\n\\n\")\n",
    "#             latent = hypers[\"latent_dim\"][l]\n",
    "#             reg = hypers[\"reg_coeff\"][r]\n",
    "#             drop = hypers[\"dropout_rate\"][d]\n",
    "#             print('Latent Dimension: {}, Reg Coeff: {}, Dropout Rate: {}'\n",
    "#                   .format(latent, reg, drop))\n",
    "\n",
    "trained = train(latent_dim=40, reg_coeff=0.0001, dropout_rate=0.5)\n",
    "\n",
    "# model.load_weights(\"dna_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 21, 1)\n",
      "Training dataset shape is (7520, 496, 21, 1)\n",
      "Test dataset shape is (1880, 496, 21, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "location = '/Users/AndrewHennes/Desktop/Code/Python/Class_Specific_Code/6.802/Project/Ensembl Datasets/New Datasets/5SpeciesProteins.csv'\n",
    "data = np.array([row for row in csv.reader(open(location, 'r'))])[1:, 1:] ## Remove the x and y axis labels.\n",
    "seq_len = len(data[0][1])//16*16\n",
    "data = np.array([[aa for aa in row[1][:seq_len]] for row in data])\n",
    "data = data[:len(data)//10]\n",
    "data = data[:len(data)//50*50]\n",
    "\n",
    "num_aa = 21\n",
    "enc = OneHotEncoder(categories = [np.array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
    "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '_'], dtype='<U1') for i in range(seq_len)],\n",
    "                    sparse = False, \n",
    "                    handle_unknown='ignore')\n",
    "\n",
    "\n",
    "one_hot = enc.fit_transform(data).reshape(-1, seq_len, num_aa, 1).astype('float32')\n",
    "train_dataset = one_hot[:len(one_hot)*4//5] # 80 Percent Training Dataset\n",
    "test_dataset = one_hot[len(one_hot)*4//5:] # 20 Percent Testing Dataset\n",
    "\n",
    "shape_of_input = train_dataset[0].shape\n",
    "print(shape_of_input)\n",
    "\n",
    "print(\"Training dataset shape is\", train_dataset.shape)\n",
    "print(\"Test dataset shape is\", test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a training_rate of 0.001, a dropout rate of 0.0, and a latent dim of 40, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1927.2818603515625, time elapse for current epoch: 0:09:45.108447\n",
      "Epoch: 2, Test set ELBO: -1906.0029296875, time elapse for current epoch: 0:09:37.341483\n",
      "Epoch: 3, Test set ELBO: -1904.478271484375, time elapse for current epoch: 0:09:42.298420\n",
      "Epoch: 4, Test set ELBO: -1903.0545654296875, time elapse for current epoch: 0:09:33.659189\n",
      "Epoch: 5, Test set ELBO: -1902.5595703125, time elapse for current epoch: 0:09:31.650460\n",
      "Epoch: 6, Test set ELBO: -1901.9940185546875, time elapse for current epoch: 0:09:33.971579\n",
      "Epoch: 7, Test set ELBO: -1901.787109375, time elapse for current epoch: 0:09:33.180841\n",
      "Epoch: 8, Test set ELBO: -1901.412109375, time elapse for current epoch: 0:09:31.668406\n",
      "Epoch: 9, Test set ELBO: -1901.3865966796875, time elapse for current epoch: 0:09:26.313177\n",
      "Epoch: 10, Test set ELBO: -1901.3507080078125, time elapse for current epoch: 0:09:24.898393\n",
      "For a training_rate of 0.001, a dropout rate of 0.0, and a latent dim of 80, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1912.4315185546875, time elapse for current epoch: 0:09:37.657641\n",
      "Epoch: 2, Test set ELBO: -1908.0745849609375, time elapse for current epoch: 0:09:33.130588\n",
      "Epoch: 3, Test set ELBO: -1906.2362060546875, time elapse for current epoch: 0:47:25.312418\n",
      "Epoch: 4, Test set ELBO: -1906.7847900390625, time elapse for current epoch: 0:09:23.946587\n",
      "Epoch: 5, Test set ELBO: -1905.1177978515625, time elapse for current epoch: 0:09:25.459479\n",
      "Epoch: 6, Test set ELBO: -1903.9766845703125, time elapse for current epoch: 0:09:27.455792\n",
      "Epoch: 7, Test set ELBO: -1905.1531982421875, time elapse for current epoch: 0:09:28.015648\n",
      "Epoch: 8, Test set ELBO: -1903.2056884765625, time elapse for current epoch: 0:09:26.775849\n",
      "Epoch: 9, Test set ELBO: -1903.970703125, time elapse for current epoch: 0:09:28.591946\n",
      "Epoch: 10, Test set ELBO: -1903.5272216796875, time elapse for current epoch: 0:09:27.065550\n",
      "For a training_rate of 0.001, a dropout rate of 0.5, and a latent dim of 40, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1823.5587158203125, time elapse for current epoch: 0:09:09.823181\n",
      "Epoch: 2, Test set ELBO: -1822.9530029296875, time elapse for current epoch: 0:09:12.358445\n",
      "Epoch: 3, Test set ELBO: -1810.619873046875, time elapse for current epoch: 0:09:12.464366\n",
      "Epoch: 4, Test set ELBO: -1803.3985595703125, time elapse for current epoch: 0:09:13.171273\n",
      "Epoch: 5, Test set ELBO: -1800.279296875, time elapse for current epoch: 0:09:13.836386\n",
      "Epoch: 6, Test set ELBO: -1799.3211669921875, time elapse for current epoch: 0:09:12.705941\n",
      "Epoch: 7, Test set ELBO: -1798.3546142578125, time elapse for current epoch: 0:09:12.545260\n",
      "Epoch: 8, Test set ELBO: -1802.988525390625, time elapse for current epoch: 0:09:12.740178\n",
      "Epoch: 9, Test set ELBO: -1858.9830322265625, time elapse for current epoch: 0:09:13.939121\n",
      "Epoch: 10, Test set ELBO: -1795.77197265625, time elapse for current epoch: 0:09:10.712783\n",
      "For a training_rate of 0.001, a dropout rate of 0.5, and a latent dim of 80, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1912.2266845703125, time elapse for current epoch: 0:09:16.834271\n",
      "Epoch: 2, Test set ELBO: -1908.2274169921875, time elapse for current epoch: 0:09:20.102838\n",
      "Epoch: 3, Test set ELBO: -1906.5189208984375, time elapse for current epoch: 0:09:20.466433\n",
      "Epoch: 4, Test set ELBO: -1905.7003173828125, time elapse for current epoch: 0:09:20.880023\n",
      "Epoch: 5, Test set ELBO: -1905.6536865234375, time elapse for current epoch: 0:09:20.992622\n",
      "Epoch: 6, Test set ELBO: -1904.2984619140625, time elapse for current epoch: 0:09:22.092373\n",
      "Epoch: 7, Test set ELBO: -1903.9716796875, time elapse for current epoch: 0:09:21.618676\n",
      "Epoch: 8, Test set ELBO: -1906.485107421875, time elapse for current epoch: 0:09:21.710299\n",
      "Epoch: 9, Test set ELBO: -1903.803466796875, time elapse for current epoch: 0:09:23.639980\n",
      "Epoch: 10, Test set ELBO: -1903.7161865234375, time elapse for current epoch: 0:09:22.185559\n",
      "For a training_rate of 0.001, a dropout rate of 0.9, and a latent dim of 40, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1913.026123046875, time elapse for current epoch: 0:09:10.818981\n",
      "Epoch: 2, Test set ELBO: -1910.9398193359375, time elapse for current epoch: 0:09:09.757931\n",
      "Epoch: 3, Test set ELBO: -1911.4688720703125, time elapse for current epoch: 0:09:11.572456\n",
      "Epoch: 4, Test set ELBO: -1913.174072265625, time elapse for current epoch: 0:09:11.017586\n",
      "Epoch: 5, Test set ELBO: -1914.9302978515625, time elapse for current epoch: 0:09:10.509008\n",
      "Epoch: 6, Test set ELBO: -1914.5430908203125, time elapse for current epoch: 0:09:09.594594\n",
      "Epoch: 7, Test set ELBO: -1916.2801513671875, time elapse for current epoch: 0:09:08.803527\n",
      "Epoch: 8, Test set ELBO: -1915.9864501953125, time elapse for current epoch: 0:09:10.009601\n",
      "Epoch: 9, Test set ELBO: -1917.0777587890625, time elapse for current epoch: 0:09:10.574916\n",
      "Epoch: 10, Test set ELBO: -1917.7177734375, time elapse for current epoch: 0:09:10.785940\n",
      "For a training_rate of 0.001, a dropout rate of 0.9, and a latent dim of 80, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1911.7528076171875, time elapse for current epoch: 0:09:18.716781\n",
      "Epoch: 2, Test set ELBO: -1907.7666015625, time elapse for current epoch: 0:09:20.687370\n",
      "Epoch: 3, Test set ELBO: -1906.2918701171875, time elapse for current epoch: 0:09:18.677957\n",
      "Epoch: 4, Test set ELBO: -1906.5296630859375, time elapse for current epoch: 0:09:20.130117\n",
      "Epoch: 5, Test set ELBO: -1903.21875, time elapse for current epoch: 0:09:20.486661\n",
      "Epoch: 6, Test set ELBO: -1904.2237548828125, time elapse for current epoch: 0:09:22.338632\n",
      "Epoch: 7, Test set ELBO: -1902.701904296875, time elapse for current epoch: 0:09:19.757485\n",
      "Epoch: 8, Test set ELBO: -1903.698486328125, time elapse for current epoch: 0:09:17.528252\n",
      "Epoch: 9, Test set ELBO: -1903.577880859375, time elapse for current epoch: 0:09:22.421588\n",
      "Epoch: 10, Test set ELBO: -1903.27880859375, time elapse for current epoch: 0:09:19.915010\n",
      "For a training_rate of 0.0001, a dropout rate of 0.0, and a latent dim of 40, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1907.947021484375, time elapse for current epoch: 0:09:12.629431\n",
      "Epoch: 2, Test set ELBO: -1905.2669677734375, time elapse for current epoch: 0:09:08.921193\n",
      "Epoch: 3, Test set ELBO: -1903.6458740234375, time elapse for current epoch: 0:09:06.831347\n",
      "Epoch: 4, Test set ELBO: -1903.3834228515625, time elapse for current epoch: 0:09:07.205255\n",
      "Epoch: 5, Test set ELBO: -1902.1280517578125, time elapse for current epoch: 0:09:07.787143\n",
      "Epoch: 6, Test set ELBO: -1901.5098876953125, time elapse for current epoch: 0:09:09.122506\n",
      "Epoch: 7, Test set ELBO: -1901.642333984375, time elapse for current epoch: 0:09:07.696009\n",
      "Epoch: 8, Test set ELBO: -1901.432373046875, time elapse for current epoch: 0:09:14.698283\n",
      "Epoch: 9, Test set ELBO: -1901.423095703125, time elapse for current epoch: 0:09:12.482716\n",
      "Epoch: 10, Test set ELBO: -1900.8458251953125, time elapse for current epoch: 0:09:17.791013\n",
      "For a training_rate of 0.0001, a dropout rate of 0.0, and a latent dim of 80, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1911.67236328125, time elapse for current epoch: 0:09:28.332464\n",
      "Epoch: 2, Test set ELBO: -1907.67138671875, time elapse for current epoch: 0:09:32.606404\n",
      "Epoch: 3, Test set ELBO: -1905.78125, time elapse for current epoch: 0:09:36.318632\n",
      "Epoch: 4, Test set ELBO: -1905.2374267578125, time elapse for current epoch: 0:09:29.879940\n",
      "Epoch: 5, Test set ELBO: -1904.5294189453125, time elapse for current epoch: 0:09:29.471152\n",
      "Epoch: 6, Test set ELBO: -1904.1666259765625, time elapse for current epoch: 0:09:30.965798\n",
      "Epoch: 7, Test set ELBO: -1903.919921875, time elapse for current epoch: 0:09:31.786087\n",
      "Epoch: 8, Test set ELBO: -1903.854248046875, time elapse for current epoch: 0:09:30.621033\n",
      "Epoch: 9, Test set ELBO: -1903.4508056640625, time elapse for current epoch: 0:09:27.881044\n",
      "Epoch: 10, Test set ELBO: -1903.03466796875, time elapse for current epoch: 0:09:36.003466\n",
      "For a training_rate of 0.0001, a dropout rate of 0.5, and a latent dim of 40, the loss over 10 epochs is:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Test set ELBO: -1927.266845703125, time elapse for current epoch: 0:09:33.533038\n",
      "Epoch: 2, Test set ELBO: -1913.327392578125, time elapse for current epoch: 0:09:27.483162\n",
      "Epoch: 3, Test set ELBO: -1909.966796875, time elapse for current epoch: 0:09:24.922501\n",
      "Epoch: 4, Test set ELBO: -1908.4083251953125, time elapse for current epoch: 0:09:29.020498\n",
      "Epoch: 5, Test set ELBO: -1909.1766357421875, time elapse for current epoch: 0:09:19.965492\n",
      "Epoch: 6, Test set ELBO: -1909.5797119140625, time elapse for current epoch: 0:09:18.721761\n",
      "Epoch: 7, Test set ELBO: -1910.177734375, time elapse for current epoch: 0:09:20.467228\n",
      "Epoch: 8, Test set ELBO: -1910.322265625, time elapse for current epoch: 0:09:18.482076\n",
      "Epoch: 9, Test set ELBO: -1911.418212890625, time elapse for current epoch: 0:09:15.542400\n",
      "Epoch: 10, Test set ELBO: -1912.019287109375, time elapse for current epoch: 0:09:31.342118\n",
      "For a training_rate of 0.0001, a dropout rate of 0.5, and a latent dim of 80, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1914.8902587890625, time elapse for current epoch: 0:09:30.172226\n",
      "Epoch: 2, Test set ELBO: -1909.0152587890625, time elapse for current epoch: 0:09:25.282599\n",
      "Epoch: 3, Test set ELBO: -1905.812255859375, time elapse for current epoch: 0:09:40.604568\n",
      "Epoch: 4, Test set ELBO: -1904.7799072265625, time elapse for current epoch: 0:09:44.080210\n",
      "Epoch: 5, Test set ELBO: -1905.1666259765625, time elapse for current epoch: 0:09:49.284975\n",
      "Epoch: 6, Test set ELBO: -1903.8599853515625, time elapse for current epoch: 0:09:46.597451\n",
      "Epoch: 7, Test set ELBO: -1904.8922119140625, time elapse for current epoch: 0:09:49.312548\n",
      "Epoch: 8, Test set ELBO: -1904.249755859375, time elapse for current epoch: 0:09:50.164169\n",
      "Epoch: 9, Test set ELBO: -1903.647216796875, time elapse for current epoch: 0:10:05.794594\n",
      "Epoch: 10, Test set ELBO: -1903.4404296875, time elapse for current epoch: 0:10:12.799883\n",
      "For a training_rate of 0.0001, a dropout rate of 0.9, and a latent dim of 40, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1908.8037109375, time elapse for current epoch: 0:10:04.515672\n",
      "Epoch: 2, Test set ELBO: -1907.5733642578125, time elapse for current epoch: 0:10:08.949298\n",
      "Epoch: 3, Test set ELBO: -1904.227783203125, time elapse for current epoch: 0:10:21.691281\n",
      "Epoch: 4, Test set ELBO: -1903.805908203125, time elapse for current epoch: 0:09:18.417971\n",
      "Epoch: 5, Test set ELBO: -1902.0301513671875, time elapse for current epoch: 0:09:16.023611\n",
      "Epoch: 6, Test set ELBO: -1902.3782958984375, time elapse for current epoch: 0:09:15.021556\n",
      "Epoch: 7, Test set ELBO: -1902.060791015625, time elapse for current epoch: 0:09:13.026924\n",
      "Epoch: 8, Test set ELBO: -1901.5709228515625, time elapse for current epoch: 0:09:14.126310\n",
      "Epoch: 9, Test set ELBO: -1900.9107666015625, time elapse for current epoch: 0:09:14.473156\n",
      "Epoch: 10, Test set ELBO: -1900.986572265625, time elapse for current epoch: 0:09:14.970727\n",
      "For a training_rate of 0.0001, a dropout rate of 0.9, and a latent dim of 80, the loss over 10 epochs is:\n",
      "Epoch: 1, Test set ELBO: -1912.7247314453125, time elapse for current epoch: 0:09:22.443905\n",
      "Epoch: 2, Test set ELBO: -1907.8154296875, time elapse for current epoch: 0:09:18.949706\n",
      "Epoch: 3, Test set ELBO: -1906.8338623046875, time elapse for current epoch: 0:09:22.067121\n",
      "Epoch: 4, Test set ELBO: -1905.478515625, time elapse for current epoch: 0:09:23.685648\n",
      "Epoch: 5, Test set ELBO: -1904.598388671875, time elapse for current epoch: 0:09:24.582177\n",
      "Epoch: 6, Test set ELBO: -1904.15380859375, time elapse for current epoch: 0:09:22.015148\n",
      "Epoch: 7, Test set ELBO: -1903.3360595703125, time elapse for current epoch: 0:09:21.660154\n",
      "Epoch: 8, Test set ELBO: -1904.0615234375, time elapse for current epoch: 0:09:21.935546\n",
      "Epoch: 9, Test set ELBO: -1904.3692626953125, time elapse for current epoch: 0:09:21.116029\n",
      "Epoch: 10, Test set ELBO: -1904.2369384765625, time elapse for current epoch: 0:09:25.798421\n"
     ]
    }
   ],
   "source": [
    "for ind1, training_rate in enumerate([1e-3, 1e-4]):\n",
    "  for ind2, dropout_rate in enumerate([0.0, 0.5, 0.9]):\n",
    "    for ind3, latent_dim in enumerate([40, 80]):\n",
    "      print(\"For a training_rate of %s, a dropout rate of %s, and a latent dim of %s, the loss over 10 epochs is:\" % (training_rate, dropout_rate, latent_dim))\n",
    "      model = train(epochs = 10, latent_dim = latent_dim, reg_coeff = 0.0001, dropout_rate = dropout_rate)\n",
    "      # results[(training_rate, dropout_rate, latent_dim)] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 0, 8, 8, 8, 12, 12, 12, 12, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 5, 5, 5, 15, 15, 15, 15, 15, 9, 15, 9, 3, 3, 14, 0, 15, 0, 0, 0, 0, 14, 14, 14, 14, 5, 5, 5, 5, 5, 5, 17, 17, 17, 17, 0, 0, 0, 0, 9, 9, 12, 12, 0, 0, 0, 16, 16, 16, 5, 2, 2, 2, 15, 15, 15, 9, 9, 11, 9, 11, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 0, 0, 2, 17, 17, 17, 13, 13, 13, 13, 13, 3, 8, 4, 3, 16, 17, 0, 0, 0, 0, 0, 0, 0, 3, 9, 9, 9, 9, 9, 9, 14, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 16, 16, 9, 9, 15, 15, 15, 15, 0, 0, 0, 3, 3, 3, 3, 3, 15, 3, 3, 9, 9, 9, 14, 12, 17, 7, 7, 7, 7, 7, 16, 3, 16, 3, 3, 12, 8, 0, 0, 0, 0, 0, 0, 0, 7, 7, 2, 8, 8, 8, 15, 8, 9, 9, 12, 12, 12, 2, 9, 9, 9, 9, 9, 9, 9, 16, 16, 16, 16, 16, 15, 16, 15, 15, 15, 3, 3, 3, 3, 3, 17, 12, 17, 17, 17, 15, 15, 5, 16, 5, 16, 16, 9, 9, 9, 9, 7, 7, 8, 8, 8, 12, 12, 12, 15, 12, 12, 15, 15, 15, 15, 15, 7, 7, 2, 2, 3, 3, 5, 5, 5, 5, 5, 0, 0, 0, 0, 9, 9, 9, 9, 9, 17, 15, 9, 14, 9, 14, 16, 16, 8, 15, 15, 15, 15, 15, 15, 15, 5, 5, 5, 5, 12, 12, 12, 9, 7, 9, 11, 11, 11, 11, 11, 8, 0, 0, 0, 0, 0, 15, 8, 13, 13, 13, 13, 9, 9, 9, 7, 7, 7, 17, 17, 17, 17, 17, 17, 0, 0, 13, 13, 16, 13, 13, 13, 7, 7, 5, 9, 17, 17, 15, 15, 15, 8, 8, 9, 9, 9, 17, 17, 17, 17, 17, 17, 2, 20, 20, 20, 2, 17, 17, 17, 0, 0, 11, 11, 17, 7, 0, 4, 4, 4, 4, 3, 14, 14, 14, 14, 20, 8, 9, 8, 8, 8, 9, 9, 9, 12, 12, 12, 12, 16, 16, 20, 20, 20, 20, 20, 20, 20, 15, 15, 15, 15, 13, 13, 15, 9, 3, 3, 3, 3, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 9, 9, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n"
     ]
    }
   ],
   "source": [
    "aas = ['*', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
    "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "sample = model.sample().numpy()[0]\n",
    "sample = np.argmax(sample, axis = 1)\n",
    "print(list(sample.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
