{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "6qW5T3SoIiU7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import tensorflow_probability as tfp\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from IPython.display import clear_output\n",
    "\n",
    "'''\n",
    "Sourced from Tensorflow's tutorial on Variational Autoencoders.\n",
    "'''\n",
    "\n",
    "class CVAE(tf.keras.Model):\n",
    "  \"\"\"Convolutional variational autoencoder.\"\"\"\n",
    "\n",
    "  def __init__(self, latent_dim, seq_len, num_aa, dropout_rate): #CHANGED\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.encoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(1, seq_len, num_aa)), #CHANGED\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=(1, 10), strides= 2, activation='relu'), #CHANGED\n",
    "            tf.keras.layers.Dropout(rate = dropout_rate),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=(1, 10), strides= 2, activation='relu'), #CHANGED\n",
    "            tf.keras.layers.Dropout(rate = dropout_rate),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=(1, 10), strides= 2, activation='relu'), #CHANGED\n",
    "            tf.keras.layers.Dropout(rate = dropout_rate),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=32, kernel_size=(1, 10), strides= 2, activation='relu'), #CHANGED\n",
    "            tf.keras.layers.Dropout(rate = dropout_rate),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128),\n",
    "            tf.keras.layers.Dense(latent_dim + latent_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            tf.keras.layers.Dense(units=1*seq_len//16*32, activation=tf.nn.relu), #CHANGED\n",
    "            tf.keras.layers.Reshape(target_shape=(1, seq_len//16, 32)),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=32, kernel_size=(1, 10), strides= (1, 2), padding='same', #CHANGED\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=(1, 10), strides= (1, 2), padding='same', #CHANGED\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=(1, 10), strides= (1, 2), padding='same', #CHANGED\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=64, kernel_size=(1, 10), strides= (1, 2), padding='same', #CHANGED\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=21, kernel_size=3, strides=1, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode(eps, apply_sigmoid=True)\n",
    "\n",
    "  def encode(self, x):\n",
    "    mean, logvar = tf.split(self.encoder(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode(self, z, apply_sigmoid=False):\n",
    "    logits = self.decoder(z)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "SA_CfZ5cJFt1"
   },
   "outputs": [],
   "source": [
    "##\n",
    "debug = True\n",
    "Train = True\n",
    "prot_length_perc_cutoff = 70\n",
    "##\n",
    "\n",
    "## from TF_VAE import CVAE\n",
    "'''\n",
    "Sourced from Tensorflow's tutorial on VAEs.\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "  log2pi = tf.math.log(2. * np.pi)\n",
    "  return tf.reduce_sum(\n",
    "      -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
    "      axis=raxis)\n",
    "\n",
    "\n",
    "def compute_loss(model, x):\n",
    "  mean, logvar = model.encode(x)\n",
    "  z = model.reparameterize(mean, logvar)\n",
    "  x_logit = model.decode(z)\n",
    "  cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
    "  logpx_z = -tf.reduce_mean(cross_ent, axis=[1, 2, 3])\n",
    "  \n",
    "  logpz = log_normal_pdf(z, 0., 0.)\n",
    "  logqz_x = log_normal_pdf(z, mean, logvar)\n",
    "  # -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "  return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
    "\n",
    "def train_step(model, x, optimizer):\n",
    "  \"\"\"Executes one training step and returns the loss.\n",
    "  This function computes the loss and gradients, and uses the latter to\n",
    "  update the model's parameters.\n",
    "  \"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = compute_loss(model, x)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "def train(epochs = 100, latent_dim=50, training_rate = 1e-4, dropout_rate = 0.5):\n",
    "    losses = []\n",
    "    optimizer = tf.keras.optimizers.Adam(training_rate)\n",
    "    model = CVAE(latent_dim, seq_len = seq_len, num_aa = 21, dropout_rate = dropout_rate) ##Num aa includes \"_\"\n",
    "    _train_step = tf.function(train_step) ## CHANGED\n",
    "    for epoch in range(1, epochs + 1):\n",
    "      start_time = time.time()\n",
    "      for train_x in train_dataset:\n",
    "        _train_step(model, train_x, optimizer)\n",
    "      end_time = time.time()\n",
    "      loss = tf.keras.metrics.Mean()\n",
    "      for test_x in test_dataset:\n",
    "        loss(compute_loss(model, test_x))\n",
    "      elbo = -loss.result()\n",
    "      losses.append(elbo)\n",
    "      # display.clear_output(wait=False)\n",
    "      print('Epoch: {}, Test set ELBO: {}, time elapse for current epoch: {}'\n",
    "            .format(epoch, elbo, end_time - start_time))\n",
    "    return model, losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhtEOQKsB6wE",
    "outputId": "b1118912-c7ff-4928-c13e-106f38c493dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape is (150, 50, 1, 288, 21)\n",
      "Test dataset shape is (38, 50, 1, 288, 21)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "location = '/Users/AndrewHennes/Desktop/Code/Python/Class_Specific_Code/6.802/Project/Ensembl Datasets/New Datasets/5SpeciesProteins.csv'\n",
    "data = np.array([row for row in csv.reader(open(location, 'r'))])[1:, 1:] ## Remove the x and y axis labels.\n",
    "seq_len = min(len(data[0][1]), 300)//16*16 ## CHANGE BACK!!\n",
    "data = np.array([[aa for aa in row[1][:seq_len]] for row in data])\n",
    "data = data[:len(data)//10]\n",
    "data = data[:len(data)//50*50]\n",
    "\n",
    "num_aa = 21\n",
    "enc = OneHotEncoder(categories = [np.array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
    "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y', '_'], dtype='<U1') for i in range(seq_len)],\n",
    "                    sparse = False, \n",
    "                    handle_unknown='ignore')\n",
    "\n",
    "\n",
    "one_hot = enc.fit_transform(data).reshape(-1, 50, 1, seq_len, num_aa).astype('float32')\n",
    "train_dataset = one_hot[:len(one_hot)*4//5] # 80 Percent Training Dataset\n",
    "test_dataset = one_hot[len(one_hot)*4//5:] # 20 Percent Testing Dataset\n",
    "print(\"Training dataset shape is\", train_dataset.shape)\n",
    "print(\"Test dataset shape is\", test_dataset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPSrKBJoexD2",
    "outputId": "12b8d7fa-283c-43cf-84a9-122b6e10eda9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0  0  5  0  9  9  9  9  9  9  9  9  9  9  9  9  0  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  0  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n",
      "   9  9  9  9  9  9  9  9 15  9  9  9  9  9  9  9]]\n",
      "(1, 1, 288, 21)\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 1, 496, 21) for input Tensor(\"input_74:0\", shape=(None, 1, 496, 21), dtype=float32), but it was called on an input with incompatible shape (1, 1, 288, 21).\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [1,320], In[1]: [736,128] [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-9b617fe7ab13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m288\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-82-617fb3e85c9d>\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_or_size_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    715\u001b[0m                                 ' implement a `call` method.')\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m     return self._run_internal_graph(\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    967\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   5575\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5576\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5577\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5578\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5579\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtranspose_a\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [1,320], In[1]: [736,128] [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "aas = ['*', 'A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
    "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "sample = model.sample().numpy()\n",
    "sample = np.argmax(sample, axis = 3)\n",
    "print(sample[0])\n",
    "print(one_hot[0][0].reshape(1, 1, 288, 21).shape)\n",
    "for i in range(10):\n",
    "    a = one_hot[i][0].reshape(1, 1, 288, 21)\n",
    "    mean, logvar = model.encode(a)\n",
    "    sample = model.decode(mean)\n",
    "    sample = np.argmax(sample, axis = 3)\n",
    "    print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-b933f04eeb3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "a, b = tf.constant([1, 2, 3, 4])\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwfpLmAkXHgN",
    "outputId": "40a63964-b112-43fb-8691-8c5106ffd547"
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for ind1, training_rate in enumerate([1e-3, 1e-4]):\n",
    "  for ind2, dropout_rate in enumerate([0.0, 0.5, 0.9]):\n",
    "    for ind3, latent_dim in enumerate([40, 80]):\n",
    "      print(\"For a training_rate of %s, a dropout rate of %s, and a latent dim of %s, the loss over 100 epochs is:\" % (training_rate, dropout_rate, latent_dim))\n",
    "      model, losses = train(latent_dim = latent_dim, training_rate = training_rate, dropout_rate = dropout_rate)\n",
    "      results[(training_rate, dropout_rate, latent_dim)] = losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "6AF7wS7Kq5Yo",
    "outputId": "df6364bb-b94f-49a6-a78e-450fee599c48"
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "for ind1, training_rate in enumerate([1e-4]):\n",
    "  for ind2, dropout_rate in enumerate([0.0, 0.5, 0.9]):\n",
    "    for ind3, latent_dim in enumerate([40, 100]):\n",
    "      print(\"For a training_rate of %s, a dropout rate of %s, and a latent dim of %s, the loss over 100 epochs is:\" % (training_rate, dropout_rate, latent_dim))\n",
    "      model, losses = train(latent_dim = latent_dim, training_rate = training_rate, dropout_rate = dropout_rate)\n",
    "      results[(training_rate, dropout_rate, latent_dim)] = losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-6f614e1d4e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0.001, 0.0, 40): [-1790.5707, -1789.6794, -1786.7626, -1787.9448, -1785.2084, -1784.0507, -1783.5522, -1783.8016, -1783.0607, -1783.7692, -1783.4398, -1782.6387, -1783.0658, -1783.4341, -1782.3354, -1782.3458, -1783.2943, -1782.4447, -1782.0837, -1781.8798, -1782.9958, -1782.2377, -1781.7018, -1783.9497, -1782.0614, -1782.0466, -1781.4056, -1781.8307, -1781.6782, -1781.5577, -1781.8972, -1782.5903, -1782.1842, -1783.1013, -1781.4486, -1781.8625, -1782.1094, -1781.476, -1781.697, -1782.9884, -1786.0206, -1781.8312, -1782.914, -1784.4685, -1781.8132, -1783.3301, -1782.321, -1783.8785, -1782.1566, -1784.0618, -1782.1826, -1782.0687, -1782.2238, -1783.1028, -1784.215, -1783.7091, -1784.1252, -1782.667, -1783.2996, -1782.2134, -1782.6747, -1782.8258, -1783.8694, -1785.8668, -1782.1346, -1781.4915, -1782.648, -1782.3585, -1785.0575, -1782.8269, -1784.8578, -1784.2999, -1787.8481, -1783.1556, -1783.746, -1783.4237, -1782.6327, -1781.7089, -1781.3628, -1781.4161, -1783.1666, -1781.644, -1781.8916, -1781.7786, -1782.131, -1782.7148, -1782.5526, -1781.5275, -1782.7651, -1782.2501, -1783.2135, -1782.8899, -1781.6398, -1782.2535, -1781.521, -1781.4417, -1784.6979, -1781.6744, -1781.4879, -1786.6753], (0.001, 0.0, 100): [-1899.0681, -1896.5608, -1895.7186, -1894.8928, -1894.4277, -1897.5521, -1894.4603, -1894.2139, -1894.4575, -1893.9252, -1893.8276, -1893.9515, -1893.8573, -1893.7188, -1893.5963, -1893.6401, -1893.8633, -1893.6467, -1893.62, -1893.5388, -1893.4067, -1893.3418, -1893.75, -1893.406, -1893.4651, -1893.3596, -1893.5793, -1893.3965, -1893.5074, -1893.2955, -1893.1957, -1893.1901, -1893.2826, -1893.2777, -1893.2936, -1893.3086, -1893.1841, -1893.2593, -1893.2952, -1893.7339, -1893.2775, -1893.5039, -1893.2094, -1893.2909, -1893.3816, -1893.126, -1893.2433, -1893.1948, -1893.1891, -1893.3478, -1893.1339, -1893.369, -1893.2067, -1893.156, -1893.2797, -1893.265, -1893.2987, -1893.2717, -1893.3213, -1893.2196, -1893.2262, -1893.3672, -1893.2225, -1893.1782, -1893.294, -1893.196, -1893.4182, -1893.2426, -1893.1719, -1893.0657, -1893.1873, -1893.2734, -1893.6322, -1893.2683, -1893.113, -1893.2085, -1893.2897, -1893.1252, -1893.0637, -1893.0663, -1893.1802, -1893.0569, -1893.325, -1893.267, -1893.3126, -1894.4335, -1893.1934, -1894.118, -1893.0048, -1893.1659, -1893.1279, -1893.1705, -1892.9939, -1893.4323, -1893.3346, -1894.7725, -1893.2114, -1893.6426, -1893.3193, -1893.0662], (0.001, 0.5, 40): [-1791.0708, -1787.891, -1786.4338, -1784.8566, -1784.8477, -1786.1807, -1783.982, -1783.6931, -1817.0713, -1783.188, -1783.4409, -1782.9869, -1782.9734, -1782.6956, -1783.0812, -1782.5514, -1782.7637, -1781.9756, -1783.3134, -1783.8179, -1782.5237, -1782.1581, -1782.1299, -1781.7272, -1781.6338, -1783.5409, -1782.6565, -1781.9565, -1781.7064, -1783.9893, -1782.051, -1781.8765, -1781.7017, -1783.3157, -1781.374, -1781.8842, -1782.731, -1783.3177, -1782.4335, -1782.1611, -1782.0707, -1781.6873, -1782.2495, -1781.9103, -1782.5577, -1783.6835, -1782.4515, -1782.1632, -1782.0546, -1782.1178, -1782.7363, -1781.7765, -1783.8154, -1782.1095, -1782.916, -1800.6237, -1782.0815, -1782.0793, -1781.8007, -1782.7151, -1781.899, -1784.4098, -1781.9854, -1781.938, -1781.9594, -1782.5902, -1784.6145, -1782.1572, -1783.8011, -1781.812, -1782.9724, -1781.577, -1783.7618, -1782.5105, -1781.9418, -1782.0181, -1782.1855, -1783.8057, -1782.8346, -1784.2517, -1783.2463, -1782.0848, -1794.3491, -1782.9111, -1785.1367, -1782.6099, -1785.0808, -1783.7427, -1782.2734, -1783.7349, -1782.1958, -1782.0819, -1784.7917, -1783.8318, -1782.1665, -1782.7561, -1781.6127, -1781.8807, -1782.2953, -1782.5376], (0.001, 0.5, 100): [-1795.2262, -1793.4163, -1794.2703, -1790.6244, -1788.6053, -1787.7411, -1787.1294, -1786.2755, -1786.1769, -1785.6772, -1784.8928, -1788.9277, -1784.2505, -1784.5698, -1783.8706, -1785.0897, -1785.0897, -1783.7449, -1783.9231, -1784.3766, -1783.7245, -1783.3838, -1783.3995, -1783.0929, -1783.0046, -1784.1487, -1783.9182, -1784.6501, -1782.8457, -1784.8082, -1783.49, -1783.2567, -1782.3702, -1782.496, -1783.0405, -1782.9072, -1783.5116, -1782.5853, -1783.2603, -1783.03, -1782.8435, -1783.8234, -1782.9364, -1782.6218, -1783.269, -1782.5817, -1782.9174, -1782.5997, -1782.7345, -1782.803, -1782.353, -1783.1575, -1782.6656, -1782.0201, -1782.7816, -1786.4095, -1782.7343, -1784.9572, -1782.7748, -1782.3792, -1788.0895, -1783.0853, -1782.7208, -1789.1392, -1782.4543, -1783.16, -1783.4542, -1793.5908, -1782.5759, -1782.7021, -1782.2897, -1782.9851, -1782.5089, -1784.4124, -1782.4242, -1782.9282, -1785.8542, -1783.505, -1782.9635, -1782.5167, -1785.638, -1782.4989, -1784.8752, -1782.5164, -1783.9539, -1782.5074, -1784.3915, -1783.6464, -1782.4562, -1783.4476, -1782.3602, -1782.8135, -1782.4668, -1782.3608, -1782.523, -1782.3142, -1783.239, -1783.0472, -1782.0804, -1783.021], (0.001, 0.9, 40): [-1898.4176, -1896.2856, -1895.2582, -1894.2927, -1894.3619, -1893.9664, -1894.2168, -1893.9326, -1893.8463, -1893.6458, -1893.4276, -1893.5181, -1893.6666, -1893.3395, -1893.3915, -1893.6884, -1893.1317, -1893.2355, -1893.4343, -1893.2511, -1893.3207, -1893.0723, -1893.3359, -1893.3228, -1893.1155, -1893.6099, -1893.2972, -1893.2048, -1893.2566, -1893.1055, -1893.1829, -1893.2518, -1893.1768, -1893.1144, -1893.122, -1892.9154, -1893.1119, -1893.0112, -1893.0272, -1893.1794, -1893.0032, -1893.0061, -1892.8489, -1892.9683, -1892.8997, -1892.956, -1892.9573, -1892.9083, -1892.9546, -1892.9716, -1892.9347, -1893.0804, -1893.4055, -1893.1873, -1893.0706, -1893.249, -1893.1014, -1893.2942, -1893.1759, -1892.99, -1893.1278, -1893.1138, -1892.956, -1893.1373, -1892.9193, -1893.1002, -1892.9187, -1893.345, -1893.0366, -1893.163, -1893.5485, -1893.24, -1893.028, -1893.0978, -1892.8345, -1892.8417, -1892.9274, -1892.9042, -1892.8602, -1893.1481, -1893.07, -1892.991, -1892.9106, -1892.9253, -1893.0392, -1893.0164, -1892.9694, -1893.1171, -1892.9529, -1893.0072, -1892.9049, -1892.9758, -1892.9453, -1892.8813, -1892.8242, -1892.9323, -1892.9446, -1892.8975, -1892.8347, -1892.7966], (0.001, 0.9, 100): [-1795.9655, -1789.8414, -1790.7102, -1788.6205, -1787.3602, -1787.3866, -1785.9099, -1785.6627, -1787.3568, -1785.1105, -1784.5844, -1787.788, -1784.353, -1784.9064, -1783.8693, -1783.9313, -1783.8136, -1783.7806, -1783.9683, -1784.2529, -1783.5094, -1784.8076, -1788.3654, -1783.7932, -1783.2518, -1783.0094, -1783.0667, -1782.7295, -1782.6431, -1782.6259, -1783.1399, -1782.3922, -1782.7808, -1782.5542, -1782.2546, -1782.8352, -1782.9086, -1783.2512, -1782.2616, -1781.9178, -1783.5757, -1781.8899, -1782.4536, -1782.526, -1782.6067, -1782.3816, -1783.2228, -1781.7618, -1782.3462, -1782.175, -1782.4641, -1783.5697, -1782.4142, -1782.142, -1782.5917, -1782.2883, -1782.7308, -1783.2361, -1782.5133, -1784.218, -1782.4443, -1783.0966, -1782.3099, -1783.8643, -1782.2645, -1782.3817, -1783.8353, -1929.6959, -1898.935, -1897.2615, -1896.6816, -1895.6282, -1895.1183, -1894.699, -1894.5122, -1894.5908, -1894.2593, -1894.2039, -1894.8136, -1894.1085, -1894.0131, -1893.7958, -1894.7285, -1893.7648, -1893.9701, -1893.9792, -1893.8783, -1893.7693, -1893.4839, -1894.093, -1893.8019, -1893.3213, -1893.6094, -1893.3694, -1893.8374, -1893.3916, -1893.4526, -1893.4766, -1893.4294, -1893.3082], (0.0001, 0.0, 40): [-1943.3756, -1796.6185, -1789.8295, -1787.3547, -1786.3422, -1784.6638, -1783.7285, -1783.5045, -1783.339, -1782.8593, -1782.5952, -1782.4108, -1782.6074, -1782.1538, -1782.2816, -1782.0055, -1781.8346, -1781.703, -1781.779, -1781.737, -1781.4448, -1781.7202, -1782.1367, -1781.0521, -1781.4214, -1781.568, -1781.03, -1781.1392, -1781.3466, -1781.3229, -1781.2548, -1781.3367, -1780.6125, -1781.0737, -1780.973, -1780.8241, -1780.9807, -1780.5996, -1780.592, -1781.7047, -1780.3981, -1780.8088, -1781.8252, -1780.351, -1780.6647, -1780.4696, -1781.7517, -1780.4296, -1780.6112, -1780.7618, -1780.235, -1780.2219, -1780.7014, -1780.202, -1780.3281, -1780.4003, -1780.6628, -1780.8646, -1780.3054, -1780.218, -1781.6371, -1781.3489, -1780.5562, -1780.585, -1780.3889, -1780.1057, -1780.2878, -1782.3949, -1780.1682, -1780.3668, -1780.3188, -1780.6464, -1780.0654, -1780.6187, -1780.2401, -1780.1779, -1780.3846, -1780.0597, -1780.2832, -1780.3274, -1780.1278, -1781.7714, -1780.2489, -1780.1464, -1780.8148, -1780.1698, -1780.4072, -1780.3354, -1780.2463, -1780.3438, -1780.309, -1782.0415, -1780.0963, -1780.3555, -1780.0936, -1781.4293, -1780.0415, -1780.7128, -1780.3842, -1781.6456]}\n"
     ]
    }
   ],
   "source": [
    "new_results = {}\n",
    "for res in results:\n",
    "    new_results[res] = [el.numpy() for el in results[res]]\n",
    "print(new_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6802CAE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
